#!/usr/bin/env python3
"""
Link Manager for GitHub Pages URLs
Automatically generates and maintains LINK.txt with proper GitHub Pages URLs
for all HTML files in the repository.
"""

import os
import subprocess
import urllib.parse
from pathlib import Path


def get_repo_info():
    """Extract repository owner and name from git remote URL."""
    try:
        result = subprocess.run(
            ['git', 'config', '--get', 'remote.origin.url'],
            capture_output=True,
            text=True,
            check=True
        )
        remote_url = result.stdout.strip()

        # Handle different URL formats
        # SSH: git@github.com:owner/repo.git
        # HTTPS: https://github.com/owner/repo.git
        # Local proxy: http://local_proxy@127.0.0.1:PORT/git/owner/repo

        if 'github.com:' in remote_url:
            # SSH format
            parts = remote_url.split(':')[1].replace('.git', '').split('/')
            owner, repo = parts[0], parts[1]
        elif 'github.com/' in remote_url:
            # HTTPS format
            parts = remote_url.replace('.git', '').split('/')
            owner, repo = parts[-2], parts[-1]
        elif '/git/' in remote_url:
            # Local proxy format
            parts = remote_url.split('/git/')[1].split('/')
            owner, repo = parts[0], parts[1]
        else:
            raise ValueError(f"Unknown git remote URL format: {remote_url}")

        return owner, repo

    except subprocess.CalledProcessError as e:
        print(f"Error: Could not get git remote URL: {e}")
        return None, None
    except Exception as e:
        print(f"Error parsing git remote URL: {e}")
        return None, None


def find_html_files(root_dir='.'):
    """Find all .html files in the repository."""
    html_files = []
    root_path = Path(root_dir).resolve()

    for file_path in root_path.rglob('*.html'):
        # Get relative path from root
        rel_path = file_path.relative_to(root_path)
        html_files.append(str(rel_path))

    return sorted(html_files)


def generate_github_pages_url(owner, repo, file_path):
    """Generate GitHub Pages URL for a given file path."""
    # URL encode the path components properly
    path_parts = file_path.split('/')
    encoded_parts = [urllib.parse.quote(part) for part in path_parts]
    encoded_path = '/'.join(encoded_parts)

    return f"https://{owner}.github.io/{repo}/{encoded_path}"


def load_existing_descriptions(link_file='LINK.txt'):
    """Load existing descriptions from LINK.txt."""
    descriptions = {}

    if not os.path.exists(link_file):
        return descriptions

    try:
        with open(link_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue

                # Split on ' - ' to separate URL from description
                if ' - ' in line:
                    url, description = line.split(' - ', 1)
                    descriptions[url.strip()] = description.strip()

    except Exception as e:
        print(f"Warning: Could not read existing LINK.txt: {e}")

    return descriptions


def update_link_txt(owner, repo, html_files, link_file='LINK.txt'):
    """Update LINK.txt with all HTML file URLs."""
    # Load existing descriptions
    existing_descriptions = load_existing_descriptions(link_file)

    # Generate header
    lines = [
        f"# GitHub Pages Links for {owner}/{repo}",
        f"# Auto-generated by PythonHelpers/link_manager.py",
        ""
    ]

    # Generate entries for each HTML file
    for file_path in html_files:
        url = generate_github_pages_url(owner, repo, file_path)

        # Use existing description if available, otherwise create placeholder
        if url in existing_descriptions:
            description = existing_descriptions[url]
        else:
            filename = os.path.basename(file_path)
            description = f"[Add description for {filename}]"

        lines.append(f"{url} - {description}")

    # Write to file
    try:
        with open(link_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines) + '\n')

        print(f"[SUCCESS] Successfully updated {link_file}")
        print(f"  - Found {len(html_files)} HTML files")
        print(f"  - Preserved {len([d for d in existing_descriptions.values() if not d.startswith('[Add description')])} existing descriptions")
        print(f"  - Added {len([url for file_path in html_files if generate_github_pages_url(owner, repo, file_path) not in existing_descriptions])} new entries")

        return True

    except Exception as e:
        print(f"Error: Could not write to {link_file}: {e}")
        return False


def main():
    """Main function to update LINK.txt."""
    print("Link Manager - GitHub Pages URL Generator")
    print("=" * 50)

    # Get repository info
    print("\n1. Getting repository information...")
    owner, repo = get_repo_info()

    if not owner or not repo:
        print("Error: Could not determine repository owner/name")
        return 1

    print(f"   Repository: {owner}/{repo}")

    # Find HTML files
    print("\n2. Searching for HTML files...")
    html_files = find_html_files()

    if not html_files:
        print("   No HTML files found in repository")
        return 0

    print(f"   Found {len(html_files)} HTML files:")
    for file_path in html_files:
        print(f"     - {file_path}")

    # Update LINK.txt
    print("\n3. Updating LINK.txt...")
    success = update_link_txt(owner, repo, html_files)

    if success:
        print("\n[SUCCESS] Link management complete!")
        print("\nNext steps:")
        print("  1. Review LINK.txt for entries marked '[Add description for ...]'")
        print("  2. Update those placeholders with meaningful descriptions")
        print("  3. Commit the changes: git add LINK.txt && git commit -m 'Update LINK.txt'")
        return 0
    else:
        return 1


if __name__ == '__main__':
    exit(main())
